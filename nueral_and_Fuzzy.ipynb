{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZTbmBUdfjKdyEUGekIf3GyY652mwx4oK",
      "authorship_tag": "ABX9TyPwywHTKfERIPm1Wf5VyGlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahSaeedKhan/Tasks/blob/main/nueral_and_Fuzzy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NAME: SARAH SAEED KHAN\n",
        "#ROLLNO#FA21-RCE-006\n",
        "\n",
        "#importing all the libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets,transforms,models"
      ],
      "metadata": {
        "id": "LzSz87KL9rm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(1234)"
      ],
      "metadata": {
        "id": "IG2_D3vs9uDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_enSMEh5eqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee21964-f63b-4074-ea2c-59cacc605b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 30.8MB/s]\n",
            "Downloading train.zip to /content\n",
            " 99% 537M/543M [00:03<00:00, 159MB/s]\n",
            "100% 543M/543M [00:03<00:00, 142MB/s]\n",
            "Downloading test1.zip to /content\n",
            " 94% 255M/271M [00:01<00:00, 155MB/s]\n",
            "100% 271M/271M [00:01<00:00, 148MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# directly downloading data from Kaggle  on to colab\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME']=\"sarahsaeedkhan\"\n",
        "os.environ['KAGGLE_KEY']=\"8a98c028cb9a51465d99b43c6a9a1eef\"\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data and extract the contents from the zip file.\n",
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"/content/train.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWhv2y5D7KIp",
        "outputId": "31dc319b-2bad-4452-bbfd-8f8e8ceb9689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the folder present in the directory and creating base directory\n",
        "data_dir_list = os.listdir('/content/train')\n",
        "#print(data_dir_list)\n",
        "\n",
        "path, dirs, files = next(os.walk(\"/content/train\"))\n",
        "file_count = len(files)\n",
        "print(file_count)\n",
        "\n",
        "original_dataset_dir = '/content/train'\n",
        "base_dir = '/content/PetImages'\n",
        "os.mkdir(base_dir) #make base directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_a2tILT8na8",
        "outputId": "ea441323-2a51-4755-b628-0a2d34274408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create directory paths\n",
        "# creating three folders from one(TRAIN TEST AND VALIDATION)\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)"
      ],
      "metadata": {
        "id": "ygW4qX448xjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(8000)]\n",
        "for fname in fnames:\n",
        "   src = os.path.join(original_dataset_dir, fname)\n",
        "   dst = os.path.join(train_cats_dir, fname)\n",
        "   #print(src,dst)\n",
        "   shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(8000,11000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "  dst = os.path.join(validation_cats_dir, fname)\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(11000, 12300)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "  dst = os.path.join(test_cats_dir, fname)\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(8000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "  dst = os.path.join(train_dogs_dir, fname)\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(8000,11000)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "  dst = os.path.join(validation_dogs_dir, fname)\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(11000, 12300)]\n",
        "for fname in fnames:\n",
        "  src = os.path.join(original_dataset_dir, fname)\n",
        "  dst = os.path.join(test_dogs_dir, fname)\n",
        "  shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "TmDlWfAS830T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the number of images in each folder\n",
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVsanH3O9AN_",
        "outputId": "4ff826c5-75df-4bb5-eae7-7043ef0a03fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training cat images: 8550\n",
            "total training dog images: 8550\n",
            "total validation cat images: 3049\n",
            "total validation dog images: 3049\n",
            "total test cat images: 1300\n",
            "total test dog images: 1300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data Augumentation\n",
        "# resize the images to overcome overfitting our model\n",
        "train_transforms =  transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "     transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "    ])"
      ],
      "metadata": {
        "id": "ScZB348u9h6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##loading datasets\n",
        "from PIL import Image\n",
        "class dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,file_list,transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    #dataset length\n",
        "    def __len__(self):\n",
        "        self.filelength = len(self.file_list)\n",
        "        return self.filelength\n",
        "\n",
        "    #load an one of images\n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img_transformed = self.transform(img)\n",
        "\n",
        "        label = img_path.split('/')[-1].split('.')[0]\n",
        "        if label == 'dog':\n",
        "            label=1\n",
        "        elif label == 'cat':\n",
        "            label=0\n",
        "\n",
        "        return img_transformed,label"
      ],
      "metadata": {
        "id": "xT9Gofn393X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(train_dir,transform=train_transforms)\n",
        "val_data = datasets.ImageFolder(validation_dir,transform=test_transforms)\n",
        "test_data = datasets.ImageFolder(test_dir,transform=test_transforms)"
      ],
      "metadata": {
        "id": "8k_ZXmmu98ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))#length of train data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUh_zBltA7Yq",
        "outputId": "fbd53d0f-9090-457e-d842-4b029b777578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = 1500,shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 10,shuffle = True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size = 600,shuffle = True)"
      ],
      "metadata": {
        "id": "rW2iQh1p-v6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5HMyHdF-wu5",
        "outputId": "5f327ba1-ff75-46fd-ccab-5b42f0a17636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17100 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(val_data), len(val_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vClkXdWF-zw6",
        "outputId": "d3c2275f-b271-4eb5-df8d-9cb84e64de3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6098 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check our images shape\n",
        "train_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5OL72-4-3pV",
        "outputId": "0503004d-03c4-480f-c532-3b9fc447e79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# build Model\n",
        "# 3 Convolution layer and 2 fully connected layer\n",
        "# batchNormalization for limit overfitting\n",
        "class Cnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Cnn,self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "            )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(3*3*64,10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(10,2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "gzpe3LQm-8Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Cnn().to(device)#model summary\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBGFQmEI_DKp",
        "outputId": "ebea6bdb-24d9-4f03-e361-5aec5f90fcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cnn(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Linear(in_features=576, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(params = model.parameters(),lr=0.001)#defining otimizers and hyper parameters\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "3e-zDRh6_HK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainning  the model\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):#train dataset\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "        epoch_accuracy += acc/len(train_loader)\n",
        "        epoch_loss += loss/len(train_loader)\n",
        "\n",
        "    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n",
        "\n",
        "\n",
        "    with torch.no_grad():#validation dataset\n",
        "        epoch_val_accuracy=0\n",
        "        epoch_val_loss =0\n",
        "        for data, label in val_loader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            val_output = model(data)\n",
        "            val_loss = criterion(val_output,label)\n",
        "\n",
        "\n",
        "            acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
        "            epoch_val_accuracy += acc/ len(val_loader)\n",
        "            epoch_val_loss += val_loss/ len(val_loader)\n",
        "\n",
        "        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch+1, epoch_val_accuracy,epoch_val_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjBzV6Mc_UCG",
        "outputId": "3a607664-bac3-4dec-9088-2bd5ad2eb1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, train accuracy : 0.5998055338859558, train loss : 0.6593274474143982\n",
            "Epoch : 1, val_accuracy : 0.6482127904891968, val_loss : 0.6309503316879272\n",
            "Epoch : 2, train accuracy : 0.6507499814033508, train loss : 0.627074122428894\n",
            "Epoch : 2, val_accuracy : 0.6838188171386719, val_loss : 0.5993415713310242\n",
            "Epoch : 3, train accuracy : 0.6823055148124695, train loss : 0.5985215306282043\n",
            "Epoch : 3, val_accuracy : 0.6915460824966431, val_loss : 0.5818554759025574\n",
            "Epoch : 4, train accuracy : 0.6968610882759094, train loss : 0.5765940546989441\n",
            "Epoch : 4, val_accuracy : 0.7124922871589661, val_loss : 0.5654087662696838\n",
            "Epoch : 5, train accuracy : 0.7189167141914368, train loss : 0.5568379163742065\n",
            "Epoch : 5, val_accuracy : 0.7228881120681763, val_loss : 0.5418285131454468\n",
            "Epoch : 6, train accuracy : 0.7168888449668884, train loss : 0.5495006442070007\n",
            "Epoch : 6, val_accuracy : 0.7179839611053467, val_loss : 0.55143141746521\n",
            "Epoch : 7, train accuracy : 0.7290555238723755, train loss : 0.5390500426292419\n",
            "Epoch : 7, val_accuracy : 0.7396506071090698, val_loss : 0.5223931670188904\n",
            "Epoch : 8, train accuracy : 0.7311111092567444, train loss : 0.5293776392936707\n",
            "Epoch : 8, val_accuracy : 0.7482096552848816, val_loss : 0.514724850654602\n",
            "Epoch : 9, train accuracy : 0.7333055734634399, train loss : 0.5309199690818787\n",
            "Epoch : 9, val_accuracy : 0.7424365282058716, val_loss : 0.5233546495437622\n",
            "Epoch : 10, train accuracy : 0.7425000071525574, train loss : 0.515580952167511\n",
            "Epoch : 10, val_accuracy : 0.7577922344207764, val_loss : 0.49324914813041687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10#test dataset\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "\n",
        "    for data, label in test_loader:\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "        epoch_accuracy += acc/len(test_loader)\n",
        "        epoch_loss += loss/len(test_loader)\n",
        "\n",
        "    print('Epoch : {}, test accuracy : {}, test loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBKzphF_bS3",
        "outputId": "a676449b-42f8-470f-c584-59b9bc1a4817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, test accuracy : 0.5934615135192871, test loss : 0.6669334769248962\n",
            "Epoch : 2, test accuracy : 0.6496152877807617, test loss : 0.6256524324417114\n",
            "Epoch : 3, test accuracy : 0.6365382671356201, test loss : 0.6279505491256714\n",
            "Epoch : 4, test accuracy : 0.654999852180481, test loss : 0.6122523546218872\n",
            "Epoch : 5, test accuracy : 0.6761535406112671, test loss : 0.5977608561515808\n",
            "Epoch : 6, test accuracy : 0.6676921248435974, test loss : 0.5938078165054321\n",
            "Epoch : 7, test accuracy : 0.6903840899467468, test loss : 0.5872085690498352\n",
            "Epoch : 8, test accuracy : 0.7015383243560791, test loss : 0.5752211213111877\n",
            "Epoch : 9, test accuracy : 0.7015381455421448, test loss : 0.5705613493919373\n",
            "Epoch : 10, test accuracy : 0.7042301297187805, test loss : 0.5631405711174011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l3FRjMEhGMM_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}